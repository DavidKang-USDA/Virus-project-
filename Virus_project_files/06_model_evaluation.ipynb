{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,re,json\n",
    "import polars as pl\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# really quickly aggregate the model summaries for plotting and such\n",
    "models = os.listdir('./models/prod')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = [e for e in models if re.match(r'.+\\.json', e)]\n",
    "\n",
    "out = []\n",
    "for j in metrics:\n",
    "    with open(f'./models/prod/{j}', 'r') as f:\n",
    "        out.append(json.load(f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = {\n",
    "     'file':[],\n",
    "     'model':[],\n",
    "     'target':[],\n",
    "     'kmer':[],\n",
    "     'contig':[],\n",
    "     'fold':[],\n",
    "    }\n",
    "\n",
    "for e in metrics:\n",
    "    _ = e.split('__')[0].split('-')\n",
    "    tmp['file'].append(e)\n",
    "    tmp['model'].append(_[0])\n",
    "    tmp['target'].append(_[1])\n",
    "    tmp['kmer'].append(_[2])\n",
    "    tmp['contig'].append(_[3])\n",
    "    tmp['fold'].append(_[4])\n",
    "\n",
    "\n",
    "metrics = pl.concat([\n",
    "    pl.DataFrame(tmp),\n",
    "    pl.concat([pl.DataFrame(e) for e in out])\n",
    "    ], \n",
    "    how='horizontal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.write_parquet('./models/prod/all__metrics.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = [e for e in models if re.match(r'.+fold\\d+__.+\\.parquet', e)]\n",
    "\n",
    "p = predictions[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _parse_filename(fn):\n",
    "    _ = fn.split('__')[0].split('-')\n",
    "    tmp = {'file': [fn],\n",
    "    'model': [_[0]],\n",
    "    'target': [_[1]],\n",
    "    'kmer': [_[2]],\n",
    "    'contig': [_[3]],\n",
    "    'fold': [_[4]]}\n",
    "    return(tmp)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parse file name as df, join with data save as list and concat\n",
    "_ = [(pl.DataFrame(_parse_filename(fn=p)).with_columns(join_on_this = pl.lit(True))\n",
    " .join(pl.read_parquet(f\"./models/prod/{p}\").with_columns(join_on_this = pl.lit(True)), \n",
    "       on='join_on_this').drop(pl.col('join_on_this'))\n",
    "       ) for p in predictions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = pl.concat(_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions.write_parquet('./models/prod/all__predictions.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = (\n",
    "    predictions\n",
    "    .filter(pl.col('TestSet') == True)\n",
    "    .drop('file', 'TestSet')\n",
    "    .group_by([pl.col(e) for e in ['model', 'target', 'kmer', 'contig', 'Header', 'Label']])\n",
    "    .agg(\n",
    "        pl.col('Yhat').sum(), \n",
    "        pl.col('ProbPos').mean(), \n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = _.pivot('target', index = ['model', 'kmer', 'contig', 'Header', 'Label'], values= ['Yhat', 'ProbPos'])\n",
    "_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_.write_parquet('./models/prod/all_agg_pivot__predictions.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what are the best models for each species?\n",
    "\n",
    "# use metrics to get the best models to examine\n",
    "\n",
    "_ = (metrics\n",
    ".select(  ['model', 'target', 'kmer', 'contig', 'fold', 'accuracy_tst'])\n",
    ".group_by(['model', 'target', 'kmer', 'contig'])\n",
    ".agg(pl.col('accuracy_tst').mean())\n",
    ")\n",
    "\n",
    "best_models = (_\n",
    "               .group_by(['model', 'target'])\n",
    "               .agg(pl.col('accuracy_tst').max())\n",
    "               ).join(_, how='inner', on=['model',  'target', 'accuracy_tst'])\n",
    "\n",
    "best_models = best_models.select(['model',  'target', 'kmer', 'contig', 'accuracy_tst'])\n",
    "best_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_models.write_csv('./models/prod/all_best_models_summary.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all the predictions from only the best models \n",
    "_ = (\n",
    "    best_models\n",
    "    .drop('accuracy_tst')\n",
    "    .join(\n",
    "        (predictions\n",
    "         .filter(pl.col('TestSet') == True)\n",
    "         .drop('file', 'TestSet')\n",
    "        ), how= 'left', on = ['model',  'target', 'kmer', 'contig'])\n",
    ")\n",
    "_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we only need the target to identify the parameters so we can select very few cols\n",
    "_ = _.select('model', 'target', 'Header', 'Label', 'Yhat', 'ProbPos').group_by(['model', 'target', 'Header', 'Label']).agg(\n",
    "    pl.col('Yhat').mean(), \n",
    "    pl.col('ProbPos').mean(), \n",
    ")\n",
    "\n",
    "_ \n",
    "# ).pivot('target', index = ['model', 'target', 'Header', 'Label'], values= ['Yhat', 'ProbPos'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# based on the shape fo the dfs there are ever so slightly more than 13 observations being collapsed. This could be from slight imballences in cvs.\n",
    "# _.select('Yhat').unique()\n",
    "\n",
    "442994/33890"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# per target model == label\n",
    "\n",
    "# example for one model \n",
    "(\n",
    "    _\n",
    "    .filter(pl.col('Yhat') > 0.5)\n",
    "    .filter(pl.col('target') == 'Vitis_vinifera')\n",
    "    .group_by('Label')\n",
    "    .count()\n",
    ")\n",
    "\n",
    "# .group_by('Label', )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_models_pospred = (\n",
    "    _\n",
    "    .filter(pl.col('Yhat') > 0.5)\n",
    "    .group_by('target', 'Label')\n",
    "    .len()\n",
    "    .sort('target', 'Label')\n",
    ")\n",
    "best_models_pospred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_models_pospred.write_csv('./models/prod/all_best_models_pospred_summary.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What are the ones we're suprised by?\n",
    "# these are the ones that should be followed up.\n",
    "best_models_falsepos = (\n",
    "    _\n",
    "    .filter(pl.col('Yhat') > 0.5)\n",
    "    .filter(pl.col('target') != pl.col('Label'))\n",
    "    .sort('target', 'Label')\n",
    ")\n",
    "\n",
    "best_models_falsepos.write_csv('./models/prod/all_best_models_falsepos.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from   ax.service.ax_client import AxClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# really quickly aggregate the model summaries for plotting and such\n",
    "axs = os.listdir('./models/tune')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _parse_filename(fn):\n",
    "    _ = fn.split('__')[0].split('-')\n",
    "    tmp = {'file': [fn],\n",
    "    'model': [_[0]],\n",
    "    'target': [_[1]],\n",
    "    'kmer': [_[2]],\n",
    "    'contig': [_[3]],\n",
    "    'fold': [_[4]]}\n",
    "    return(tmp)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_parse_filename(fn = j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "j = axs[0]\n",
    "\n",
    "_ = []\n",
    "for j in axs:\n",
    "\n",
    "    ax_client = (AxClient.load_from_json_file(filepath = f\"./models/tune/{j}\"))\n",
    "\n",
    "    hyps = pl.DataFrame(ax_client.get_trials_data_frame())\n",
    "\n",
    "    hyps = pl.DataFrame(_parse_filename(fn=j)).with_columns(join_on_this = pl.lit(True)).join(\n",
    "                                hyps.with_columns(join_on_this = pl.lit(True)),\n",
    "                                on='join_on_this').drop(pl.col('join_on_this'))\n",
    "    _.append(hyps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = pl.concat(_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_.write_parquet('./models/prod/all__hyperparameters.parquet')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
